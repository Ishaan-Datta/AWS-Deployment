Public subnets: host resources that need to be directly accessible from the internet, such as Load Balancers (like the one created by the AWS Load Balancer Controller). The EKS worker nodes in this architecture are placed in both public and private subnets. The public subnets allow the EKS worker nodes to be directly accessible by the internet if needed, but more importantly, they enable the creation of the public-facing Application Load Balancer (ALB). The ALB needs to be in a public subnet to route external traffic to your application.

Private subnets: host resources that do not need to be directly accessible from the internet, such as backend services and databases (e.g., the RDS instance). In this setup, your backend services (like the authorization service, recommendation service, and RDS) are deployed within private subnets to restrict direct internet access. This reduces the attack surface and improves security since these services can only be accessed internally within the VPC (Virtual Private Cloud).

Internet gateway: An Internet Gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between your VPC and the internet. The IGW enables resources within the public subnet to send and receive traffic from the internet. Without an IGW, resources in the VPC could not access the internet, making it impossible for external users to reach your public-facing services.

Route table: The public subnet's route table has a route that directs all outbound traffic (`0.0.0.0/0`) to the IGW. This route allows instances in the public subnet to communicate with the internet. This setup ensures that traffic destined for the internet is correctly routed through the IGW. Without this route, even though an IGW is attached to the VPC, instances would not be able to reach the internet.

Access from the internet: 
with ingress: Typically used when you have multiple services that need to be exposed to the internet, and you want to manage routing rules, SSL termination, etc., at a single point.
- with ALB: The AWS Load Balancer Controller, which is deployed in your EKS cluster, automatically creates an Application Load Balancer (ALB) in the public subnets. The ALB has a public IP address and DNS name, making it accessible over the internet.
- ingress resource definition: Kubernetes Ingress resources define how external HTTP(S) requests should be routed to services within your cluster. In the provided Kubernetes manifests, the Ingress resource is configured with rules that map incoming requests to specific services (e.g., frontend, authorization, recommendation) based on the requested hostnames (like `frontend.example.com`, `auth.example.com`).
- DNS resolution: Users would access your application using domain names (e.g., `frontend.example.com`). These domain names should point to the ALB’s DNS name via DNS A or CNAME records. When a user accesses one of these domain names, the DNS system resolves the name to the ALB’s public IP, and the ALB routes the request to the appropriate service in your EKS cluster based on the Ingress rules.
- traffic flow: **External User** → **Domain Name (e.g., frontend.example.com)** → **DNS Resolves to ALB** → **ALB (in Public Subnet)** → **EKS Service (Internal Private Subnet)** → **Pod (Microservice)**.

without ingress: If your architecture only requires external traffic to be directed to the front-end service, and internal services are meant to stay internal (only accessible within the cluster or VPC), you can simplify your setup by using an external Application Load Balancer (ALB) directly without deploying an Ingress controller.
- **Kubernetes Service of Type LoadBalancer**: Deploy your front-end service with a Kubernetes `Service` of type `LoadBalancer`. Kubernetes automatically provisions an ALB in the public subnets of your VPC when you create a `Service` of type `LoadBalancer` on AWS. The ALB is linked directly to the front-end service, meaning all incoming traffic to the ALB is routed to the front-end pods.
- **Security Groups**: Ensure the ALB security group allows inbound traffic on the necessary ports (e.g., port 80 for HTTP or port 443 for HTTPS). Internal services do not need to be exposed, so they should be configured with `ClusterIP` services, ensuring that they are only accessible from within the Kubernetes cluster.
- traffic flow: **External User** → **ALB** → **Frontend Service** (Kubernetes `Service` of type `LoadBalancer`) → **Frontend Pods**.